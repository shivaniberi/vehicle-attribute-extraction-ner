{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKyVc3xUcxu3",
        "outputId": "a493a77d-2377-4ed5-9c79-4f51e7d42dc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DEVICE\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_conll(path):\n",
        "    sentences, labels = [], []\n",
        "    temp_x, temp_y = [], []\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "\n",
        "            # Sentence boundary\n",
        "            if not line:\n",
        "                if temp_x:\n",
        "                    sentences.append(temp_x)\n",
        "                    labels.append(temp_y)\n",
        "                    temp_x, temp_y = [], []\n",
        "                continue\n",
        "\n",
        "            parts = line.split()\n",
        "\n",
        "            # Last item = tag\n",
        "            tag = parts[-1]\n",
        "\n",
        "            # Everything except last = token (joined in case it's multi-word)\n",
        "            token = \" \".join(parts[:-1])\n",
        "\n",
        "            temp_x.append(token)\n",
        "            temp_y.append(tag)\n",
        "\n",
        "    # Catch last sentence\n",
        "    if temp_x:\n",
        "        sentences.append(temp_x)\n",
        "        labels.append(temp_y)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "train_sentences, train_labels = read_conll(\"/content/FindVehicle_train.txt\")\n",
        "test_sentences, test_labels = read_conll(\"/content/FindVehicle_test.txt\")\n",
        "\n",
        "print(\"Train sentences:\", len(train_sentences))\n",
        "print(\"Test sentences:\", len(test_sentences))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VNMZgfXczjO",
        "outputId": "4f16a929-d037-4d76-ad77-2010907fe064"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train sentences: 21565\n",
            "Test sentences: 20777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_TOKEN = \"<PAD>\"\n",
        "UNK_TOKEN = \"<UNK>\"\n",
        "\n",
        "def build_vocab(sentences):\n",
        "    vocab = {PAD_TOKEN:0, UNK_TOKEN:1}\n",
        "    for sent in sentences:\n",
        "        for tok in sent:\n",
        "            if tok not in vocab:\n",
        "                vocab[tok] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "def build_tag_vocab(labels):\n",
        "    tag2idx = {PAD_TOKEN:0}\n",
        "    for seq in labels:\n",
        "        for tag in seq:\n",
        "            if tag not in tag2idx:\n",
        "                tag2idx[tag] = len(tag2idx)\n",
        "    return tag2idx\n",
        "\n",
        "word2idx = build_vocab(train_sentences)\n",
        "tag2idx = build_tag_vocab(train_labels)\n",
        "idx2tag = {v:k for k,v in tag2idx.items()}\n",
        "\n",
        "print(\"Vocab size:\", len(word2idx))\n",
        "print(\"Tag size:\", len(tag2idx))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QX0p-yic1Fr",
        "outputId": "1f103472-7bb9-4d3b-d71d-a4f99b8703b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 3703\n",
            "Tag size: 59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NERDataset(Dataset):\n",
        "    def __init__(self, sentences, labels, word2idx, tag2idx):\n",
        "        self.sentences = sentences\n",
        "        self.labels = labels\n",
        "        self.word2idx = word2idx\n",
        "        self.tag2idx = tag2idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def encode_sentence(self, sent):\n",
        "        return torch.tensor([self.word2idx.get(t,1) for t in sent], dtype=torch.long)\n",
        "\n",
        "    def encode_labels(self, tags):\n",
        "        return torch.tensor([self.tag2idx[t] for t in tags], dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.encode_sentence(self.sentences[idx])\n",
        "        y = self.encode_labels(self.labels[idx])\n",
        "        return x, y, len(x)\n",
        "\n",
        "def collate(batch):\n",
        "    xs, ys, lens = zip(*batch)\n",
        "    lens = torch.tensor(lens)\n",
        "\n",
        "    xs_pad = pad_sequence(xs, batch_first=True, padding_value=0)\n",
        "    ys_pad = pad_sequence(ys, batch_first=True, padding_value=0)\n",
        "\n",
        "    lens_sorted, perm = lens.sort(descending=True)\n",
        "    xs_pad = xs_pad[perm]\n",
        "    ys_pad = ys_pad[perm]\n",
        "\n",
        "    return xs_pad, ys_pad, lens_sorted, perm\n",
        "\n",
        "train_dataset = NERDataset(train_sentences, train_labels, word2idx, tag2idx)\n",
        "test_dataset  = NERDataset(test_sentences, test_labels, word2idx, tag2idx)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate)\n"
      ],
      "metadata": {
        "id": "y4bN3yUZc2uj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BiLSTM"
      ],
      "metadata": {
        "id": "iP31IdzLc-ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#BiLSTM\n",
        "\n",
        "vocab_size = len(word2idx)\n",
        "tagset_size = len(tag2idx)\n",
        "pad_idx = word2idx[PAD_TOKEN]\n",
        "\n",
        "embedding_dim = 100\n",
        "hidden_dim = 128\n",
        "lstm_hidden = hidden_dim // 2   # because bidirectional\n",
        "\n",
        "embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx).to(DEVICE)\n",
        "\n",
        "bilstm = nn.LSTM(\n",
        "    input_size=embedding_dim,\n",
        "    hidden_size=lstm_hidden,\n",
        "    batch_first=True,\n",
        "    bidirectional=True\n",
        ").to(DEVICE)\n",
        "\n",
        "classifier = nn.Linear(hidden_dim, tagset_size).to(DEVICE)\n",
        "\n",
        "def forward_bilstm(x, lens):\n",
        "    emb = embedding(x)\n",
        "    packed = pack_padded_sequence(emb, lens.cpu(), batch_first=True, enforce_sorted=False)\n",
        "    packed_out, _ = bilstm(packed)\n",
        "    out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
        "    logits = classifier(out)\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "Pu7-8_aRc4C2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "bnuQBe3LdAk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab_size = len(word2idx)\n",
        "# tagset_size = len(tag2idx)\n",
        "# pad_idx = word2idx[PAD_TOKEN]\n",
        "\n",
        "# embedding_dim = 100\n",
        "# hidden_dim = 128\n",
        "\n",
        "# embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx).to(DEVICE)\n",
        "\n",
        "# bilstm = nn.LSTM(\n",
        "#     input_size=embedding_dim,\n",
        "#     hidden_size=hidden_dim,\n",
        "#     batch_first=True,\n",
        "#     bidirectional=False\n",
        "# ).to(DEVICE)\n",
        "\n",
        "# classifier = nn.Linear(hidden_dim, tagset_size).to(DEVICE)\n",
        "\n",
        "# def forward_bilstm(x, lens):\n",
        "#     emb = embedding(x)\n",
        "#     packed = pack_padded_sequence(emb, lens.cpu(), batch_first=True, enforce_sorted=False)\n",
        "#     packed_out, _ = bilstm(packed)\n",
        "#     out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
        "#     logits = classifier(out)\n",
        "#     return logits"
      ],
      "metadata": {
        "id": "ZgKBUbdGc6w3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=tag2idx[PAD_TOKEN])\n",
        "params = list(embedding.parameters()) + list(bilstm.parameters()) + list(classifier.parameters())\n",
        "optimizer = torch.optim.Adam(params, lr=1e-3)\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total = 0\n",
        "    for x_batch, y_batch, lens, perm in train_loader:\n",
        "\n",
        "        x_batch = x_batch.to(DEVICE)\n",
        "        y_batch = y_batch.to(DEVICE)\n",
        "        lens = lens.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = forward_bilstm(x_batch, lens)\n",
        "        loss = criterion(logits.view(-1, tagset_size), y_batch.view(-1))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {total/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s_2rNIoc50D",
        "outputId": "48d9cc2b-32c6-4f0b-bc79-2dcbe08f67dd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Loss: 0.4031\n",
            "Epoch 2/10 - Loss: 0.1071\n",
            "Epoch 3/10 - Loss: 0.0589\n",
            "Epoch 4/10 - Loss: 0.0331\n",
            "Epoch 5/10 - Loss: 0.0196\n",
            "Epoch 6/10 - Loss: 0.0127\n",
            "Epoch 7/10 - Loss: 0.0089\n",
            "Epoch 8/10 - Loss: 0.0061\n",
            "Epoch 9/10 - Loss: 0.0051\n",
            "Epoch 10/10 - Loss: 0.0036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model():\n",
        "    true_all, pred_all = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch, lens, perm in test_loader:\n",
        "\n",
        "            x_batch = x_batch.to(DEVICE)\n",
        "            y_batch = y_batch.to(DEVICE)\n",
        "            lens = lens.to(DEVICE)\n",
        "\n",
        "            logits = forward_bilstm(x_batch, lens)\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            inv = torch.argsort(perm)\n",
        "            preds = preds[inv]\n",
        "            y_batch = y_batch[inv]\n",
        "            lens = lens[inv]\n",
        "\n",
        "            pad_tag = tag2idx[PAD_TOKEN]\n",
        "\n",
        "            for i in range(preds.size(0)):\n",
        "                L = lens[i].item()\n",
        "                for t, p in zip(y_batch[i][:L], preds[i][:L]):\n",
        "                    if t.item() != pad_tag:\n",
        "                        true_all.append(t.item())\n",
        "                        pred_all.append(p.item())\n",
        "\n",
        "    acc = accuracy_score(true_all, pred_all)\n",
        "    prec = precision_score(true_all, pred_all, average=\"macro\", zero_division=0)\n",
        "    rec  = recall_score(true_all, pred_all, average=\"macro\", zero_division=0)\n",
        "    f1   = f1_score(true_all, pred_all, average=\"macro\", zero_division=0)\n",
        "\n",
        "    print(\"Accuracy :\", round(acc,4))\n",
        "    print(\"Avg Precision :\", round(prec,4))\n",
        "    print(\"Avg Recall :\", round(rec,4))\n",
        "    print(\"Avg F1 :\", round(f1,4))\n",
        "\n",
        "evaluate_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S84HkH8c7Ti",
        "outputId": "9afb9f32-f88e-4523-9024-0d13693f916e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.9961\n",
            "Avg Precision : 0.9733\n",
            "Avg Recall : 0.9683\n",
            "Avg F1 : 0.9705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(tokens):\n",
        "    encoded = torch.tensor(\n",
        "        [word2idx.get(t, word2idx[UNK_TOKEN]) for t in tokens],\n",
        "        dtype=torch.long\n",
        "    ).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    lens = torch.tensor([len(tokens)], dtype=torch.long).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = forward_bilstm(encoded, lens)\n",
        "        preds = torch.argmax(logits, dim=-1)[0].cpu().tolist()\n",
        "\n",
        "    return list(zip(tokens, [idx2tag[p] for p in preds]))\n",
        "\n",
        "example = [\"Find\", \"the\", \"Silver\", \"van\", \"in\", \"the\", \"Top-Left\"]\n",
        "predict(example)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyAmEr86c9D_",
        "outputId": "007a267f-76ff-4025-9352-ad24facce8dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Find', 'O'),\n",
              " ('the', 'O'),\n",
              " ('Silver', 'B-vehicle_type'),\n",
              " ('van', 'B-vehicle_type'),\n",
              " ('in', 'O'),\n",
              " ('the', 'O'),\n",
              " ('Top-Left', 'B-vehicle_location')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0xCI3m8aomC",
        "outputId": "db8f326d-836a-44ee-9eca-df1499715619"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from seqeval) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=2545a5ebebd87e7a73203450ca62216b2f0b6872c7d6ee4453ead5a34f409f2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import (\n",
        "    classification_report,\n",
        "    f1_score as seq_f1,\n",
        "    precision_score as seq_precision,\n",
        "    recall_score as seq_recall,\n",
        "    accuracy_score as seq_accuracy\n",
        ")\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate_keras_style():\n",
        "    all_true_tags = []\n",
        "    all_pred_tags = []\n",
        "\n",
        "    all_true_token = []\n",
        "    all_pred_token = []\n",
        "\n",
        "    PAD_idx = tag2idx[PAD_TOKEN]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch, lens, perm in test_loader:\n",
        "\n",
        "            x_batch = x_batch.to(DEVICE)\n",
        "            y_batch = y_batch.to(DEVICE)\n",
        "            lens = lens.to(DEVICE)\n",
        "\n",
        "            logits = forward_bilstm(x_batch, lens)\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            # Restore original order\n",
        "            inv = torch.argsort(perm)\n",
        "            preds = preds[inv]\n",
        "            y_batch = y_batch[inv]\n",
        "            lens = lens[inv]\n",
        "\n",
        "            for i in range(preds.size(0)):\n",
        "                L = lens[i].item()\n",
        "\n",
        "                seq_true_tags = []\n",
        "                seq_pred_tags = []\n",
        "\n",
        "                for t, p in zip(y_batch[i][:L], preds[i][:L]):\n",
        "                    t = t.item()\n",
        "                    p = p.item()\n",
        "\n",
        "                    if t == PAD_idx:\n",
        "                        continue\n",
        "\n",
        "                    seq_true_tags.append(idx2tag[t])\n",
        "                    seq_pred_tags.append(idx2tag[p])\n",
        "\n",
        "                    # for token-level accuracy\n",
        "                    all_true_token.append(t)\n",
        "                    all_pred_token.append(p)\n",
        "\n",
        "                all_true_tags.append(seq_true_tags)\n",
        "                all_pred_tags.append(seq_pred_tags)\n",
        "\n",
        "    # ============================\n",
        "    #  ENTITY-LEVEL (SEQEVAL)\n",
        "    # ============================\n",
        "    print(\"\\nEntity-level Evaluation (seqeval)\\n\")\n",
        "    print(classification_report(all_true_tags, all_pred_tags, digits=4))\n",
        "\n",
        "    ent_precision = seq_precision(all_true_tags, all_pred_tags)\n",
        "    ent_recall    = seq_recall(all_true_tags, all_pred_tags)\n",
        "    ent_f1        = seq_f1(all_true_tags, all_pred_tags)\n",
        "    ent_accuracy  = seq_accuracy(all_true_tags, all_pred_tags)   # <-- entity-level accuracy\n",
        "\n",
        "    print(\"Entity-level Precision:\", ent_precision)\n",
        "    print(\"Entity-level Recall:   \", ent_recall)\n",
        "    print(\"Entity-level F1 Score: \", ent_f1)\n",
        "    print(\"Entity-level Accuracy: \", ent_accuracy)\n",
        "\n",
        "    # ============================\n",
        "    #  TOKEN-LEVEL (SKLEARN)\n",
        "    # ============================\n",
        "    token_accuracy = accuracy_score(all_true_token, all_pred_token)\n",
        "    print(\"\\nToken-level Accuracy:\", token_accuracy)\n",
        "\n",
        "    return ent_precision, ent_recall, ent_f1, ent_accuracy, token_accuracy\n",
        "\n",
        "evaluate_keras_style()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyFOM1YUbHK0",
        "outputId": "ea6c575a-cf4c-4618-8754-6db7a2672173"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entity-level Evaluation (seqeval)\n",
            "\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "           vehicle_brand     1.0000    0.9999    0.9999     14396\n",
            "           vehicle_color     1.0000    0.9999    0.9999     15776\n",
            "        vehicle_location     1.0000    1.0000    1.0000      9287\n",
            "           vehicle_model     0.9998    0.9999    0.9998     14395\n",
            "     vehicle_orientation     1.0000    0.9998    0.9999      4987\n",
            "           vehicle_range     1.0000    1.0000    1.0000       181\n",
            "            vehicle_type     1.0000    0.9993    0.9997      1451\n",
            "        vehicle_type-bus     0.8659    0.8634    0.8646       344\n",
            "      vehicle_type-coupe     0.8335    0.8852    0.8586       854\n",
            " vehicle_type-estate_car     0.7395    0.8361    0.7848       421\n",
            "  vehicle_type-hatchback     0.7792    0.8249    0.8014      1279\n",
            " vehicle_type-motorcycle     0.9759    0.9831    0.9794      2302\n",
            "        vehicle_type-mpv     0.7421    0.8497    0.7923       386\n",
            "   vehicle_type-roadster     0.6676    0.7841    0.7212       315\n",
            "      vehicle_type-sedan     0.7839    0.9275    0.8497      3035\n",
            " vehicle_type-sports_car     0.9402    0.9535    0.9468      1484\n",
            "        vehicle_type-suv     0.8937    0.9007    0.8972      1914\n",
            "      vehicle_type-truck     0.8583    0.9276    0.8916       594\n",
            "        vehicle_type-van     0.7716    0.8231    0.7965       390\n",
            "vehicle_type-vintage_car     0.8801    0.9026    0.8912      1293\n",
            "        vehicle_velocity     1.0000    0.9992    0.9996      6597\n",
            "\n",
            "               micro avg     0.9718    0.9837    0.9777     81681\n",
            "               macro avg     0.8920    0.9266    0.9083     81681\n",
            "            weighted avg     0.9741    0.9837    0.9786     81681\n",
            "\n",
            "Entity-level Precision: 0.9717948717948718\n",
            "Entity-level Recall:    0.9836804152740539\n",
            "Entity-level F1 Score:  0.9777015228673468\n",
            "Entity-level Accuracy:  0.9940432856077152\n",
            "\n",
            "Token-level Accuracy: 0.9940432856077152\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.9717948717948718),\n",
              " np.float64(0.9836804152740539),\n",
              " np.float64(0.9777015228673468),\n",
              " 0.9940432856077152,\n",
              " 0.9940432856077152)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uGaf0EqTbbQ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}